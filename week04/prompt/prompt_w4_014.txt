src/orchestrator.py íŒŒì¼ì„ ìƒˆë¡œ ìƒì„±í•˜ê³ 
AutonomousOrchestrator í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•´ì£¼ì„¸ìš”.

[íŒŒì¼ ìœ„ì¹˜]
src/orchestrator.py

[êµ¬í˜„ ë‚´ìš©]

"""
ììœ¨ ì‹¤í–‰ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
TaskPlanner, ReActEngine, QualityManagerë¥¼ ì¡°ìœ¨í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""
from typing import Dict, Any, List, Optional
from openai import OpenAI
import logging

from src.task_planner import TaskPlanner, TaskStatus
from src.react_engine import ReActEngine
from src.quality_manager import QualityManager
from src.search_agent import SearchAgent
from src.memory_manager import MemoryManager
from config.prompts import SYNTHESIS_PROMPT

logger = logging.getLogger(__name__)


class AutonomousOrchestrator:
    """ììœ¨ ì‹¤í–‰ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    def __init__(self, client: OpenAI, memory_manager: Optional[MemoryManager] = None, search_agent: Optional[SearchAgent] = None):
        self.client = client
        
        self.memory_manager = memory_manager or MemoryManager(
            collection_name="orchestrator_memory",
            persist_directory="data/chroma_db"
        )
        self.search_agent = search_agent or SearchAgent(memory_manager=self.memory_manager)
        
        self.task_planner = TaskPlanner(client)
        self.quality_manager = QualityManager(client)
        
        self.tools = self._create_tool_registry()
        self.react_engine = ReActEngine(client, self.tools)
        
        self.execution_log: List[Dict] = []
        logger.info("AutonomousOrchestrator initialized")
    
    def _create_tool_registry(self) -> Dict[str, callable]:
        """ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìƒì„±"""
        
        def search_web(query: str) -> str:
            result = self.search_agent.search(query)
            return self.search_agent.format_for_llm(result)
        
        def search_memory(query: str) -> str:
            results = self.memory_manager.search_memory(query, top_k=5)
            if not results:
                return "ë©”ëª¨ë¦¬ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            return "\n".join([f"- {r['text'][:200]}..." for r in results])
        
        def store_knowledge(text: str) -> str:
            doc_id = self.memory_manager.add_to_memory(text, metadata={"source": "autonomous_agent"})
            return f"ì§€ì‹ ì €ì¥ ì™„ë£Œ (ID: {doc_id})"
        
        def analyze(data: str) -> str:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ì •ë³´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•µì‹¬ì„ ìš”ì•½í•˜ì„¸ìš”."},
                    {"role": "user", "content": f"ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{data}"}
                ],
                temperature=0.5
            )
            return response.choices[0].message.content
        
        return {
            "search_web": search_web,
            "search_memory": search_memory,
            "store_knowledge": store_knowledge,
            "analyze": analyze,
        }
    
    def execute(self, goal: str, verbose: bool = True) -> str:
        """ëª©í‘œ ì‹¤í–‰"""
        if verbose:
            print(f"\nğŸ¯ ëª©í‘œ: {goal}")
            print("="*60)
        
        # 1. ì‘ì—… ë¶„í•´
        if verbose:
            print("\nğŸ“‹ Step 1: ì‘ì—… ë¶„í•´ ì¤‘...")
        self.task_planner.decompose(goal)
        if verbose:
            self.task_planner.visualize()
        
        # 2. ì„œë¸ŒíƒœìŠ¤í¬ ìˆœì°¨ ì‹¤í–‰
        results = []
        
        while not self.task_planner.is_complete():
            task = self.task_planner.get_next_task()
            if not task:
                break
            
            if verbose:
                print(f"\nğŸ”„ ì‹¤í–‰ ì¤‘: [{task.id}] {task.description}")
            
            result = self._execute_with_quality(task.description, verbose)
            
            if result:
                self.task_planner.update_status(task.id, TaskStatus.COMPLETED, result)
                results.append({"task_id": task.id, "description": task.description, "result": result})
                if verbose:
                    print(f"âœ… [{task.id}] ì™„ë£Œ")
            else:
                self.task_planner.update_status(task.id, TaskStatus.FAILED)
                if verbose:
                    print(f"âŒ [{task.id}] ì‹¤íŒ¨")
        
        # 3. ê²°ê³¼ ì¢…í•©
        if verbose:
            print("\nğŸ“ Step 3: ê²°ê³¼ ì¢…í•© ì¤‘...")
        
        final_report = self._synthesize_results(results, goal)
        
        self.execution_log.append({
            "goal": goal,
            "tasks": self.task_planner.get_summary(),
            "results_count": len(results)
        })
        
        if verbose:
            print("\n" + "="*60)
            print("âœ¨ ì‘ì—… ì™„ë£Œ!")
            self.task_planner.visualize()
        
        return final_report
    
    def _execute_with_quality(self, task_description: str, verbose: bool = True) -> Optional[str]:
        """í’ˆì§ˆ í‰ê°€ì™€ í•¨ê»˜ íƒœìŠ¤í¬ ì‹¤í–‰"""
        for attempt in range(self.quality_manager.max_retries):
            self.react_engine.reset()
            result = self.react_engine.run(task_description)
            
            evaluation = self.quality_manager.evaluate(task_description, result)
            
            if verbose:
                print(f"   í’ˆì§ˆ ì ìˆ˜: {evaluation['overall']:.1f}/10")
            
            if evaluation["pass"]:
                return result
            
            if attempt < self.quality_manager.max_retries - 1:
                if verbose:
                    print(f"   ì¬ì‹œë„ ì¤‘... ({attempt + 2}/{self.quality_manager.max_retries})")
                task_description = self.quality_manager.get_improvement_prompt(task_description, result, evaluation)
        
        return result
    
    def _synthesize_results(self, results: List[Dict], goal: str) -> str:
        """ê²°ê³¼ ì¢…í•©"""
        if not results:
            return "ìˆ˜ì§‘ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        results_text = ""
        for r in results:
            results_text += f"\n### {r['description']}\n{r['result']}\n"
        
        prompt = SYNTHESIS_PROMPT.format(goal=goal, results=results_text)
        
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë¦¬ì„œì¹˜ ê²°ê³¼ ì¢…í•© ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5
        )
        
        return response.choices[0].message.content
    
    def get_stats(self) -> Dict[str, Any]:
        """ì‹¤í–‰ í†µê³„ ë°˜í™˜"""
        return {
            "total_executions": len(self.execution_log),
            "quality_stats": self.quality_manager.get_stats(),
            "last_execution": self.execution_log[-1] if self.execution_log else None
        }