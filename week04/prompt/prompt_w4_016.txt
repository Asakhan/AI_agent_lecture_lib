tests/test_orchestrator.py íŒŒì¼ì„ ìƒì„±í•˜ê³ 
Part 2ì˜ í†µí•© í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

[íŒŒì¼ ìœ„ì¹˜]
tests/test_orchestrator.py

[êµ¬í˜„ ë‚´ìš©]

"""AutonomousOrchestrator í†µí•© í…ŒìŠ¤íŠ¸"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from openai import OpenAI
from src.loop_prevention import LoopPrevention
from src.quality_manager import QualityManager
from src.react_engine import ReActEngine
from src.orchestrator import AutonomousOrchestrator


def test_loop_prevention():
    """LoopPrevention í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("TEST 1: Loop Prevention")
    print("="*50)
    
    lp = LoopPrevention(max_iterations=5, max_same_action=3)
    
    result = lp.check_loop("ìƒê°1", {"action": "search_web", "action_input": "AI"})
    assert not result["is_loop"]
    print("âœ… ì •ìƒ ì•¡ì…˜ í†µê³¼")
    
    lp.check_loop("ìƒê°2", {"action": "analyze", "action_input": "data"})
    
    for i in range(3):
        result = lp.check_loop(f"ìƒê°{i+3}", {"action": "search_web", "action_input": "same"})
    
    assert result["is_loop"]
    print("âœ… ë™ì¼ ì•¡ì…˜ ì—°ì† ê°ì§€")
    
    lp.reset()
    for i in range(6):
        result = lp.check_loop(f"ìƒê°{i}", {"action": f"action_{i}", "action_input": str(i)})
    
    assert result["should_stop"]
    print("âœ… ìµœëŒ€ ë°˜ë³µ ê°ì§€")
    
    return True


def test_quality_manager():
    """QualityManager í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("TEST 2: Quality Manager")
    print("="*50)
    
    client = OpenAI()
    qm = QualityManager(client, min_quality_score=7.0)
    
    good_result = """
    AI ë°˜ë„ì²´ ì‹œì¥ ë¶„ì„:
    1. ì‹œì¥ ê·œëª¨: 2024ë…„ ì•½ 500ì–µ ë‹¬ëŸ¬
    2. ì„±ì¥ë¥ : ì—°í‰ê·  25%
    3. ì£¼ìš” ê¸°ì—…: NVIDIA(70%), AMD, Intel
    """
    
    eval1 = qm.evaluate("AI ë°˜ë„ì²´ ì‹œì¥ ì¡°ì‚¬", good_result)
    print(f"ì¢‹ì€ ê²°ê³¼ ì ìˆ˜: {eval1['overall']:.1f}/10")
    assert eval1["overall"] >= 6
    print("âœ… ì¢‹ì€ ê²°ê³¼ í‰ê°€ ì™„ë£Œ")
    
    poor_result = "AI ì‹œì¥ì´ ì„±ì¥ ì¤‘ì…ë‹ˆë‹¤."
    eval2 = qm.evaluate("AI ë°˜ë„ì²´ ì‹œì¥ ì¡°ì‚¬", poor_result)
    print(f"ë¶€ì¡±í•œ ê²°ê³¼ ì ìˆ˜: {eval2['overall']:.1f}/10")
    print("âœ… ë¶€ì¡±í•œ ê²°ê³¼ í‰ê°€ ì™„ë£Œ")
    
    return True


def test_react_engine():
    """ReActEngine í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("TEST 3: ReAct Engine")
    print("="*50)
    
    client = OpenAI()
    
    def mock_search(query):
        return f"'{query}' ê²€ìƒ‰ ê²°ê³¼: AI ì‹œì¥ì€ 500ì–µ ë‹¬ëŸ¬ ê·œëª¨ì…ë‹ˆë‹¤."
    
    def mock_analyze(data):
        return f"ë¶„ì„ ì™„ë£Œ: {data[:50]}..."
    
    tools = {"search_web": mock_search, "analyze": mock_analyze}
    
    engine = ReActEngine(client, tools, max_iterations=5)
    result = engine.run("AI ì‹œì¥ ê·œëª¨ë¥¼ ì¡°ì‚¬í•˜ì„¸ìš”")
    
    assert result is not None
    print(f"âœ… ReAct ì‹¤í–‰ ì™„ë£Œ (ìŠ¤í… ìˆ˜: {len(engine.history)})")
    
    return True


def test_orchestrator():
    """Orchestrator í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("TEST 4: Orchestrator")
    print("="*50)
    
    client = OpenAI()
    orchestrator = AutonomousOrchestrator(client)
    
    print("ğŸ¯ ê°„ë‹¨í•œ ëª©í‘œë¡œ í…ŒìŠ¤íŠ¸ ì¤‘...")
    result = orchestrator.execute("Pythonì˜ ì¥ë‹¨ì ì„ 3ê°€ì§€ì”© ì •ë¦¬í•´ì£¼ì„¸ìš”", verbose=False)
    
    assert result is not None
    assert len(result) > 50
    print(f"âœ… ê²°ê³¼ ìƒì„±ë¨ (ê¸¸ì´: {len(result)}ì)")
    
    stats = orchestrator.get_stats()
    print(f"   ì´ ì‹¤í–‰ íšŸìˆ˜: {stats['total_executions']}")
    print("âœ… Orchestrator í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    return True


def run_all_tests():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\nğŸ§ª Part 2 í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ " + "="*30)
    
    tests = [
        ("Loop Prevention", test_loop_prevention),
        ("Quality Manager", test_quality_manager),
        ("ReAct Engine", test_react_engine),
        ("Orchestrator", test_orchestrator),
    ]
    
    results = []
    for name, test_func in tests:
        try:
            result = test_func()
            results.append((name, "PASS" if result else "FAIL"))
        except Exception as e:
            print(f"âŒ {name} ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, "ERROR"))
    
    print("\n" + "="*50)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*50)
    
    for name, status in results:
        icon = "âœ…" if status == "PASS" else "âŒ"
        print(f"{icon} {name}: {status}")
    
    passed = sum(1 for _, s in results if s == "PASS")
    print(f"\nì´ ê²°ê³¼: {passed}/{len(results)} í†µê³¼")
    
    return passed == len(results)


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)

[ì‹¤í–‰ ë°©ë²•]
python tests/test_orchestrator.py